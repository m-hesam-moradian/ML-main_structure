{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f1ad572",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ML\\Hesam= SCI-6MO-Yahyavi-Deadline=8-7-2025\\src\\Utils\\getAllMetric.py:101: RuntimeWarning: overflow encountered in cosh\n",
      "  return np.mean(np.log(np.cosh(y_pred - y_true)))\n",
      "d:\\ML\\Hesam= SCI-6MO-Yahyavi-Deadline=8-7-2025\\src\\Utils\\getAllMetric.py:101: RuntimeWarning: overflow encountered in cosh\n",
      "  return np.mean(np.log(np.cosh(y_pred - y_true)))\n",
      "d:\\ML\\Hesam= SCI-6MO-Yahyavi-Deadline=8-7-2025\\src\\Utils\\getAllMetric.py:101: RuntimeWarning: overflow encountered in cosh\n",
      "  return np.mean(np.log(np.cosh(y_pred - y_true)))\n",
      "d:\\ML\\Hesam= SCI-6MO-Yahyavi-Deadline=8-7-2025\\src\\Utils\\getAllMetric.py:101: RuntimeWarning: overflow encountered in cosh\n",
      "  return np.mean(np.log(np.cosh(y_pred - y_true)))\n",
      "d:\\ML\\Hesam= SCI-6MO-Yahyavi-Deadline=8-7-2025\\src\\Utils\\getAllMetric.py:101: RuntimeWarning: overflow encountered in cosh\n",
      "  return np.mean(np.log(np.cosh(y_pred - y_true)))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "from src.Utils.K_Fold import K_Fold\n",
    "from src.data_loader import load_data\n",
    "from src.analysis.SHAP import shap_analysis\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from src.feature_engineering import average_daily\n",
    "from objective_function import objective_adaboost\n",
    "from src.Utils.Z_Score import remove_outliers_zscore\n",
    "from src.model.train_model import get_X_y, train_model\n",
    "from src.analysis.LIME import lime_sensitivity_analysis\n",
    "from src.Optimiser.HOA.hoa_optimizer import hoa_optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5039eff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\M'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\M'\n",
      "C:\\Users\\hesam\\AppData\\Local\\Temp\\ipykernel_15300\\2261336153.py:2: SyntaxWarning: invalid escape sequence '\\M'\n",
      "  DATA_PATH = \"D:\\ML\\Hesam= SCI-6MO-Yahyavi-Deadline=8-7-2025\\data\\data.xlsx\"\n"
     ]
    }
   ],
   "source": [
    "# Load raw data\n",
    "DATA_PATH = \"D:\\ML\\Hesam= SCI-6MO-Yahyavi-Deadline=8-7-2025\\data\\data.xlsx\"\n",
    "df = load_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15a392a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z-scores:\n",
      "     Tracker Distance  Very Active Distance  Moderately Active Distance  \\\n",
      "0            0.651259              0.198319                   -0.099077   \n",
      "1            0.088207              0.292342                    0.376262   \n",
      "2           -1.373169             -0.565143                   -0.642321   \n",
      "3            0.443954             -0.565143                   -0.257523   \n",
      "4            0.610310             -0.437272                    0.183863   \n",
      "..                ...                   ...                         ...   \n",
      "935         -1.401322             -0.565143                   -0.642321   \n",
      "936         -0.966236             -0.565143                   -0.246206   \n",
      "937          0.479784             -0.365815                    1.655149   \n",
      "938          0.487462             -0.328206                    1.247716   \n",
      "939         -0.492760             -0.565143                   -0.642321   \n",
      "\n",
      "     Light Active Distance  Very Active Minutes  Fairly Active Minutes  \\\n",
      "0                 1.067883             0.147211              -0.178357   \n",
      "1                -0.343428             0.268996               0.121832   \n",
      "2                -1.583226            -0.644391              -0.678672   \n",
      "3                 1.729435            -0.644391              -0.328452   \n",
      "4                 1.690232            -0.461714               0.271927   \n",
      "..                     ...                  ...                    ...   \n",
      "935              -1.637130            -0.644391              -0.678672   \n",
      "936              -0.980479            -0.644391              -0.278420   \n",
      "937               0.690553            -0.431267               1.522714   \n",
      "938               0.857166            -0.279036               1.272557   \n",
      "939               0.102507            -0.644391              -0.678672   \n",
      "\n",
      "     Lightly Active Minutes  Sedentary Minutes     Steps  Burned Calories   \n",
      "0                  1.430617          -1.341700  0.552586          0.323588  \n",
      "1                 -0.529544           0.888876  0.071374          0.833219  \n",
      "2                 -1.656178           1.034926 -1.471533         -0.283513  \n",
      "3                  1.458096           0.284761  0.374490          0.203839  \n",
      "4                  0.597091           0.095561  0.507178          0.987779  \n",
      "..                      ...                ...       ...               ...  \n",
      "935               -1.766094           1.489671 -1.501412         -1.332016  \n",
      "936               -0.300553           0.932027 -1.005260         -1.078593  \n",
      "937                0.413898           0.530390  0.350902          0.986387  \n",
      "938                0.056673          -0.316034  0.386285          0.829042  \n",
      "939                0.249025           0.759423 -0.445418         -0.663647  \n",
      "\n",
      "[940 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# Remove outliers using the function\n",
    "cleaned_df, z_scores = remove_outliers_zscore(df, threshold=3)\n",
    "\n",
    "# Display original and cleaned DataFrame\n",
    "book = load_workbook(DATA_PATH)\n",
    "if \"Data after Z-score\" in book.sheetnames:\n",
    "    book.remove(book[\"Data after Z-score\"])\n",
    "    book.save(DATA_PATH)\n",
    "with pd.ExcelWriter(DATA_PATH, engine=\"openpyxl\", mode=\"a\") as writer:\n",
    "    cleaned_df.to_excel(writer, sheet_name=\"Data after Z-score\", index=False)\n",
    "\n",
    "\n",
    "X, y = get_X_y(cleaned_df, target_col=\"Burned Calories \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4c909a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÅ Fold 1 ------------------\n",
      "  ADAboost ‚Üí R2: 0.4823, RMSE: 202102.9122\n",
      "\n",
      "üîÅ Fold 2 ------------------\n",
      "  ADAboost ‚Üí R2: 0.4667, RMSE: 200856.6243\n",
      "\n",
      "üîÅ Fold 3 ------------------\n",
      "  ADAboost ‚Üí R2: 0.4678, RMSE: 194209.5324\n",
      "\n",
      "üîÅ Fold 4 ------------------\n",
      "  ADAboost ‚Üí R2: 0.4998, RMSE: 176575.3488\n",
      "\n",
      "üîÅ Fold 5 ------------------\n",
      "  ADAboost ‚Üí R2: 0.5366, RMSE: 180081.3100\n",
      "\n",
      "‚úÖ K-Fold Cross-Validation completed.\n",
      "Best fold index: 4, R2: 0.5366\n",
      "‚úÖ Combined DataFrame using original target column name:\n"
     ]
    }
   ],
   "source": [
    "# Apply K-Fold cross-validation\n",
    "(\n",
    "    X_train_best,\n",
    "    X_test_best,\n",
    "    y_train_best,\n",
    "    y_test_best,\n",
    "    K_Fold_Cross_Validation_Scores,\n",
    "    combined_df,\n",
    ") = K_Fold(X, y, n_splits=5)\n",
    "\n",
    "\n",
    "# Save combined K-Fold data to Excel\n",
    "book = load_workbook(DATA_PATH)\n",
    "if \"DATA after K-Fold\" in book.sheetnames:\n",
    "    book.remove(book[\"DATA after K-Fold\"])\n",
    "    book.save(DATA_PATH)\n",
    "with pd.ExcelWriter(DATA_PATH, engine=\"openpyxl\", mode=\"a\") as writer:\n",
    "    combined_df.to_excel(writer, sheet_name=\"DATA after K-Fold\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bfad224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metrics:\n",
      "R2: 0.4907\n",
      "RMSE: 190765.1456\n"
     ]
    }
   ],
   "source": [
    "# Helper function to average metrics\n",
    "def summarize_metrics(metrics_list):\n",
    "    return {key: np.mean([m[key] for m in metrics_list]) for key in metrics_list[0]}\n",
    "\n",
    "\n",
    "avg_metrics_k_fold = summarize_metrics(K_Fold_Cross_Validation_Scores)\n",
    "print(\"Average Metrics:\")\n",
    "for key, value in avg_metrics_k_fold.items():\n",
    "    print(f\"{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81143312",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ML\\Hesam= SCI-6MO-Yahyavi-Deadline=8-7-2025\\src\\Utils\\getAllMetric.py:101: RuntimeWarning: overflow encountered in cosh\n",
      "  return np.mean(np.log(np.cosh(y_pred - y_true)))\n",
      "d:\\ML\\Hesam= SCI-6MO-Yahyavi-Deadline=8-7-2025\\src\\Utils\\getAllMetric.py:101: RuntimeWarning: overflow encountered in cosh\n",
      "  return np.mean(np.log(np.cosh(y_pred - y_true)))\n",
      "d:\\ML\\Hesam= SCI-6MO-Yahyavi-Deadline=8-7-2025\\src\\Utils\\getAllMetric.py:101: RuntimeWarning: overflow encountered in cosh\n",
      "  return np.mean(np.log(np.cosh(y_pred - y_true)))\n",
      "d:\\ML\\Hesam= SCI-6MO-Yahyavi-Deadline=8-7-2025\\src\\Utils\\getAllMetric.py:101: RuntimeWarning: overflow encountered in cosh\n",
      "  return np.mean(np.log(np.cosh(y_pred - y_true)))\n",
      "d:\\ML\\Hesam= SCI-6MO-Yahyavi-Deadline=8-7-2025\\src\\Utils\\getAllMetric.py:101: RuntimeWarning: overflow encountered in cosh\n",
      "  return np.mean(np.log(np.cosh(y_pred - y_true)))\n"
     ]
    }
   ],
   "source": [
    "singleModel_result = train_model(X_train_best, y_train_best, X_test_best, y_test_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "226d2ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü•æ Iter 1/10 - Best RMSE: 353.08348\n",
      "ü•æ Iter 2/10 - Best RMSE: 353.08348\n",
      "ü•æ Iter 3/10 - Best RMSE: 351.82757\n",
      "ü•æ Iter 4/10 - Best RMSE: 351.82757\n",
      "ü•æ Iter 5/10 - Best RMSE: 351.82757\n",
      "ü•æ Iter 6/10 - Best RMSE: 350.92794\n",
      "ü•æ Iter 7/10 - Best RMSE: 350.92794\n",
      "ü•æ Iter 8/10 - Best RMSE: 350.92794\n",
      "ü•æ Iter 9/10 - Best RMSE: 350.92794\n",
      "ü•æ Iter 10/10 - Best RMSE: 350.92794\n"
     ]
    }
   ],
   "source": [
    "best_pos, best_RMSE, convergence = hoa_optimizer(\n",
    "    objective_adaboost,  # our AdaBoost objective\n",
    "    [50, 0.01],  # lower bounds: n_estimators, learning_rate\n",
    "    [300, 1.0],  # upper bounds\n",
    "    2,  # dim\n",
    "    10,  # n_agents\n",
    "    10,  # max_iter\n",
    "    X_train_best,\n",
    "    y_train_best,\n",
    "    X_test_best,\n",
    "    y_test_best,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "129583a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ML\\Hesam= SCI-6MO-Yahyavi-Deadline=8-7-2025\\src\\Utils\\getAllMetric.py:101: RuntimeWarning: overflow encountered in cosh\n",
      "  return np.mean(np.log(np.cosh(y_pred - y_true)))\n",
      "d:\\ML\\Hesam= SCI-6MO-Yahyavi-Deadline=8-7-2025\\src\\Utils\\getAllMetric.py:101: RuntimeWarning: overflow encountered in cosh\n",
      "  return np.mean(np.log(np.cosh(y_pred - y_true)))\n",
      "d:\\ML\\Hesam= SCI-6MO-Yahyavi-Deadline=8-7-2025\\src\\Utils\\getAllMetric.py:101: RuntimeWarning: overflow encountered in cosh\n",
      "  return np.mean(np.log(np.cosh(y_pred - y_true)))\n",
      "d:\\ML\\Hesam= SCI-6MO-Yahyavi-Deadline=8-7-2025\\src\\Utils\\getAllMetric.py:101: RuntimeWarning: overflow encountered in cosh\n",
      "  return np.mean(np.log(np.cosh(y_pred - y_true)))\n",
      "d:\\ML\\Hesam= SCI-6MO-Yahyavi-Deadline=8-7-2025\\src\\Utils\\getAllMetric.py:101: RuntimeWarning: overflow encountered in cosh\n",
      "  return np.mean(np.log(np.cosh(y_pred - y_true)))\n"
     ]
    }
   ],
   "source": [
    "HOA_model_result = train_model(\n",
    "    X_train_best, y_train_best, X_test_best, y_test_best, best_pos\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70caf5e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d6db996f58c4de8bd5c5c0bd16c118a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/172 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# SHAP on the HOA model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m sensitivity_df_shap, shap_values \u001b[38;5;241m=\u001b[39m \u001b[43mshap_analysis\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mHOA_model_result\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# assuming train_model returns dict with \"model\"\u001b[39;49;00m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train_best\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train_best\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_test_best\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_test_best\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDATA_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# save to same Excel file\u001b[39;49;00m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSHAP_Sensitivity\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\ML\\Hesam= SCI-6MO-Yahyavi-Deadline=8-7-2025\\src\\analysis\\SHAP.py:45\u001b[0m, in \u001b[0;36mshap_analysis\u001b[1;34m(model, X_train, y_train, X_test, y_test, save_path, sheet_name)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Create SHAP explainer\u001b[39;00m\n\u001b[0;32m     41\u001b[0m explainer \u001b[38;5;241m=\u001b[39m shap\u001b[38;5;241m.\u001b[39mKernelExplainer(\n\u001b[0;32m     42\u001b[0m     model\u001b[38;5;241m.\u001b[39mpredict, shap\u001b[38;5;241m.\u001b[39msample(X_train, \u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m     43\u001b[0m )  \u001b[38;5;66;03m# ŸÜŸÖŸàŸÜŸá 100 ÿ™ÿß ÿßÿ≤ X_train\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m shap_values \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshap_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Create SHAP values DataFrame\u001b[39;00m\n\u001b[0;32m     48\u001b[0m feature_names \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     49\u001b[0m     X_test\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X_test, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(X_test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])]\n\u001b[0;32m     52\u001b[0m )\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\shap\\explainers\\_kernel.py:275\u001b[0m, in \u001b[0;36mKernelExplainer.shap_values\u001b[1;34m(self, X, **kwargs)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep_index:\n\u001b[0;32m    274\u001b[0m     data \u001b[38;5;241m=\u001b[39m convert_to_instance_with_index(data, column_name, index_value[i : i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m], index_name)\n\u001b[1;32m--> 275\u001b[0m explanations\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgc_collect\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    277\u001b[0m     gc\u001b[38;5;241m.\u001b[39mcollect()\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\shap\\explainers\\_kernel.py:479\u001b[0m, in \u001b[0;36mKernelExplainer.explain\u001b[1;34m(self, incoming_instance, **kwargs)\u001b[0m\n\u001b[0;32m    476\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernelWeights[nfixed_samples:] \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m weight_left \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernelWeights[nfixed_samples:]\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m    478\u001b[0m \u001b[38;5;66;03m# execute the model on the synthetic samples we have created\u001b[39;00m\n\u001b[1;32m--> 479\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[38;5;66;03m# solve then expand the feature importance (Shapley value) vector to contain the non-varying features\u001b[39;00m\n\u001b[0;32m    482\u001b[0m phi \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mgroups_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mD))\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\shap\\explainers\\_kernel.py:624\u001b[0m, in \u001b[0;36mKernelExplainer.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    622\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep_index_ordered:\n\u001b[0;32m    623\u001b[0m         data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39msort_index()\n\u001b[1;32m--> 624\u001b[0m modelOut \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(modelOut, (pd\u001b[38;5;241m.\u001b[39mDataFrame, pd\u001b[38;5;241m.\u001b[39mSeries)):\n\u001b[0;32m    626\u001b[0m     modelOut \u001b[38;5;241m=\u001b[39m modelOut\u001b[38;5;241m.\u001b[39mvalues\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:1147\u001b[0m, in \u001b[0;36mAdaBoostRegressor.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1144\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1145\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_X(X)\n\u001b[1;32m-> 1147\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_median_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimators_\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:1115\u001b[0m, in \u001b[0;36mAdaBoostRegressor._get_median_predict\u001b[1;34m(self, X, limit)\u001b[0m\n\u001b[0;32m   1112\u001b[0m predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([est\u001b[38;5;241m.\u001b[39mpredict(X) \u001b[38;5;28;01mfor\u001b[39;00m est \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[:limit]])\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m   1114\u001b[0m \u001b[38;5;66;03m# Sort the predictions\u001b[39;00m\n\u001b[1;32m-> 1115\u001b[0m sorted_idx \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margsort\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1117\u001b[0m \u001b[38;5;66;03m# Find index of median prediction for each sample\u001b[39;00m\n\u001b[0;32m   1118\u001b[0m weight_cdf \u001b[38;5;241m=\u001b[39m stable_cumsum(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator_weights_[sorted_idx], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:1243\u001b[0m, in \u001b[0;36margsort\u001b[1;34m(a, axis, kind, order, stable)\u001b[0m\n\u001b[0;32m   1130\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_argsort_dispatcher)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21margsort\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, stable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1132\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m \u001b[38;5;124;03m    Returns the indices that would sort an array.\u001b[39;00m\n\u001b[0;32m   1134\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1241\u001b[0m \n\u001b[0;32m   1242\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1244\u001b[0m \u001b[43m        \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43margsort\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstable\u001b[49m\n\u001b[0;32m   1245\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Python\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# SHAP on the HOA model\n",
    "sensitivity_df_shap, shap_values = shap_analysis(\n",
    "    model=HOA_model_result[\"model\"],  # assuming train_model returns dict with \"model\"\n",
    "    X_train=X_train_best,\n",
    "    y_train=y_train_best,\n",
    "    X_test=X_test_best,\n",
    "    y_test=y_test_best,\n",
    "    save_path=DATA_PATH,  # save to same Excel file\n",
    "    sheet_name=\"SHAP_Sensitivity\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09bef291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä LIME Sensitivity for each feature:\n",
      "Very Active Minutes > 29.00: 24.7143\n",
      "5.03 < Tracker Distance <= 7.14: 11.9335\n",
      "3.27 < Light Active Distance <= 4.78: 4.8021\n",
      "Very Active Distance > 1.82: 2.8707\n",
      "Sedentary Minutes <= 738.75: 8.2220\n",
      "5.00 < Fairly Active Minutes <= 18.00: 13.5337\n",
      "197.00 < Lightly Active Minutes <= 266.00: 6.0718\n",
      "7133.50 < Steps <= 10132.75: 9.7169\n",
      "Moderately Active Distance > 0.73: 11.6844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\Python\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sensitivity_LIME = lime_sensitivity_analysis(\n",
    "    model=HOA_model_result[\"model\"],\n",
    "    X_train=X_train_best,\n",
    "    y_train=y_train_best,\n",
    "    X_test=X_test_best,\n",
    "    y_test=y_test_best,\n",
    "    sample_index=5,\n",
    "    epsilon=0.05,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67f4962",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nBest AdaBoost Params:\", best_pos)\n",
    "print(\"Best RMSE:\", best_RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d77f98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
